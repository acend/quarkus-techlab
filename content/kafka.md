# Reactive Messaging with Kafka in Quarkus

Modern web applications running a microservice architecture need information to flow through multiple microservices. We have already seen one way of communication between two microservices, we exposed a REST interface on one application and consumed it from athoner. Communication through REST is very easy to implement and understand but it has also it's downsides. 
For example what happens when our called microservice is not available. The REST call will just return a time-out and every application has to handle it's fallback by itself. 
Here the concept of Messaging comes in handy. Messaging allows our application to be loosely coupled by communicating asynchronously. It transfers the responsibility of handling the information flow between single nodes of your application to the message broker. 

## Concepts

To understand what we are talking about we have to establish some vocabulary and define core concepts. 

### Message Broker

A message broker is software that enables applications, systems, and services to communicate with each other and exchange information. The message broker does this by translating messages between formal messaging protocols. This allows interdependent services to “talk” with one another directly, even if they were written in different languages or implemented on different platforms.

Message brokers are software modules within messaging middleware or message-oriented middleware (MOM) solutions. This type of middleware provides developers with a standardized means of handling the flow of data between an application’s components so that they can focus on its core logic. It can serve as a distributed communications layer that allows applications spanning multiple platforms to communicate internally.

### Message

A Message is an envelope around a payload. Your application is going to receive, process and send Messages. These Messages can be generated by your application, or are retrieved from a message broker. They can also be consumed by your application, or sent to a message broker.

### Channels

Messaging applications transmit data through a Message Channel, a virtual pipe that connects a sender to a receiver. A newly installed messaging system doesn’t contain any channels; you must determine how your applications need to communicate and then create the channels to facilitate it.

### Queue Pattern

A Queue is defined as a point-to-point Channel (Queue), where one of multiple producers produces a message which will be consumed by exactly one available consumer. 

### Publish/Subscribe Pattern

A Topic describes a broadcast Channel (Topic), a message will be consumed by all available consumers.

### Connectors

Your application is interacting with messaging brokers or event backbone using connectors. A connector is a piece of code that connects to a broker and:

  * subscribe / poll / receive messages from the broker and propagate them to the application

  * send / write / dispatch messages provided by the application to the broker

To achieve this, connectors are configured to map incoming messages to a specific channel (consumed by the application) and to collect outgoing messages sent to a specific channel by the application. These collected messages are sent to the external broker.

## Kafka

In this Chapter we want to use Apache Kafka as our message broker. Kafka has some own concepts and introduces a ton of other functionality. But for starters were going to use it as a simple message broker. 

### Define Kafka Cluster

In this techlab you are going to set up your own Kafka cluster which will handle your messages. Add the following resource definition to your infrastructure project under `quarkus-techlab-infrastructure/src/main/openshift/kafka`: 

```yaml

apiVersion: kafka.strimzi.io/v1beta1
kind: Kafka
metadata:
  name: subzero
spec:
  kafka:
    version: 2.5.0
    replicas: 1
    listeners:
      plain: {}
      tls: {}
    config:
      auto.create.topics.enable: false
      offsets.topic.replication.factor: 1
      transaction.state.log.replication.factor: 1
      transaction.state.log.min.isr: 2
      log.message.format.version: "2.5"
    storage:
      type: jbod
      volumes:
      - id: 0
        type: persistent-claim
        size: 100Gi
        deleteClaim: false
  zookeeper:
    replicas: 1
    storage:
      type: persistent-claim
      size: 100Gi
      deleteClaim: false
  entityOperator:
    topicOperator: {}
    userOperator: {}

```

For starters we need a simple Kafka Topic `manual` which we will use as communication channel to transfer data from one microservice to another. 

```yaml

apiVersion: kafka.strimzi.io/v1beta1
kind: KafkaTopic
metadata:
  name: manual
  labels:
    strimzi.io/cluster: quarkus-techlab-user$
spec:
  partitions: 1
  replicas: 1
  config:
    retention.ms: 7200000
    segment.bytes: 1073741824

```

If you apply these manifests you can see the Kafka cluster appear in your OpenShift project.

```s

oc apply -f quarkus-techlab-infrastructure/src/main/openshift/kafka

```

